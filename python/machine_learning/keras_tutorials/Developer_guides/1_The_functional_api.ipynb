{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "figured-planning",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "together-warner",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(784,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "material-creek",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(inputs))\n",
    "print(inputs.shape)\n",
    "print(inputs.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "authorized-luther",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense = layers.Dense(64, activation=\"relu\")\n",
    "x = dense(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "received-present",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = layers.Dense(64, activation=\"relu\")(x)\n",
    "outputs = layers.Dense(10)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ignored-orchestra",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Model(inputs=inputs, outputs=outputs, name=\"mnist_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tamil-touch",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "antique-theta",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.utils.plot_model(model, \"my_first_model.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classical-quest",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.utils.plot_model(model, \"my_first_model_with_shape_info.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "manual-tribe",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(60000, 784).astype(\"float32\") / 255\n",
    "x_test = x_test.reshape(10000, 784).astype(\"float32\") / 255\n",
    "\n",
    "model.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=keras.optimizers.RMSprop(),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "history = model.fit(x_train, y_train, batch_size=64, epochs=2, validation_split=0.2)\n",
    "\n",
    "test_scores = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(\"Test loss:\", test_scores[0])\n",
    "print(\"Test accuracy:\", test_scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ignored-stock",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = keras.Input(shape=(28, 28, 1), name=\"img\")\n",
    "x = layers.Conv2D(16, 3, activation=\"relu\")(encoder_input)\n",
    "x = layers.Conv2D(32, 3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(3)(x)\n",
    "x = layers.Conv2D(32, 3, activation=\"relu\")(x)\n",
    "x = layers.Conv2D(16, 3, activation=\"relu\")(x)\n",
    "encoder_output = layers.GlobalMaxPooling2D()(x)\n",
    "\n",
    "encoder = keras.Model(encoder_input, encoder_output, name=\"encoder\")\n",
    "encoder.summary()\n",
    "\n",
    "x = layers.Reshape((4, 4, 1))(encoder_output)\n",
    "x = layers.Conv2DTranspose(16, 3, activation=\"relu\")(x)\n",
    "x = layers.Conv2DTranspose(32, 3, activation=\"relu\")(x)\n",
    "x = layers.UpSampling2D(3)(x)\n",
    "x = layers.Conv2DTranspose(16, 3, activation=\"relu\")(x)\n",
    "decoder_output = layers.Conv2DTranspose(1, 3, activation=\"relu\")(x)\n",
    "\n",
    "autoencoder = keras.Model(encoder_input, decoder_output, name=\"autoencoder\")\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fresh-portugal",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = keras.Input(shape=(28, 28, 1), name=\"original_img\")\n",
    "x = layers.Conv2D(16, 3, activation=\"relu\")(encoder_input)\n",
    "x = layers.Conv2D(32, 3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(3)(x)\n",
    "x = layers.Conv2D(32, 3, activation=\"relu\")(x)\n",
    "x = layers.Conv2D(16, 3, activation=\"relu\")(x)\n",
    "encoder_output = layers.GlobalMaxPooling2D()(x)\n",
    "\n",
    "encoder = keras.Model(encoder_input, encoder_output, name=\"encoder\")\n",
    "encoder.summary()\n",
    "\n",
    "decoder_input = keras.Input(shape=(16,), name=\"encoded_img\")\n",
    "x = layers.Reshape((4, 4, 1))(decoder_input)\n",
    "x = layers.Conv2DTranspose(16, 3, activation=\"relu\")(x)\n",
    "x = layers.Conv2DTranspose(32, 3, activation=\"relu\")(x)\n",
    "x = layers.UpSampling2D(3)(x)\n",
    "x = layers.Conv2DTranspose(16, 3, activation=\"relu\")(x)\n",
    "decoder_output = layers.Conv2DTranspose(1, 3, activation=\"relu\")(x)\n",
    "\n",
    "decoder = keras.Model(decoder_input, decoder_output, name=\"decoder\")\n",
    "decoder.summary()\n",
    "\n",
    "autoencoder_input = keras.Input(shape=(28, 28, 1), name=\"img\")\n",
    "encoded_img = encoder(autoencoder_input)\n",
    "decoded_img = decoder(encoded_img)\n",
    "autoencoder = keras.Model(autoencoder_input, decoded_img, name=\"autoencoder\")\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "saving-brooks",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    inputs = keras.Input(shape=(128,))\n",
    "    outputs = layers.Dense(1)(inputs)\n",
    "    return keras.Model(inputs, outputs)\n",
    "\n",
    "\n",
    "model1 = get_model()\n",
    "model2 = get_model()\n",
    "model3 = get_model()\n",
    "\n",
    "inputs = keras.Input(shape=(128,))\n",
    "y1 = model1(inputs)\n",
    "y2 = model2(inputs)\n",
    "y3 = model3(inputs)\n",
    "outputs = layers.average([y1, y2, y3])\n",
    "ensemble_model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "ensemble_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mineral-franchise",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tags = 12  # Number of unique issue tags\n",
    "num_words = 10000  # Size of vocabulary obtained when preprocessing text data\n",
    "num_departments = 4  # Number of departments for predictions\n",
    "\n",
    "title_input = keras.Input(\n",
    "    shape=(None,), name=\"title\"\n",
    ")  # Variable-length sequence of ints\n",
    "body_input = keras.Input(shape=(None,), name=\"body\")  # Variable-length sequence of ints\n",
    "tags_input = keras.Input(\n",
    "    shape=(num_tags,), name=\"tags\"\n",
    ")  # Binary vectors of size `num_tags`\n",
    "\n",
    "# Embed each word in the title into a 64-dimensional vector\n",
    "title_features = layers.Embedding(num_words, 64)(title_input)\n",
    "# Embed each word in the text into a 64-dimensional vector\n",
    "body_features = layers.Embedding(num_words, 64)(body_input)\n",
    "\n",
    "# Reduce sequence of embedded words in the title into a single 128-dimensional vector\n",
    "title_features = layers.LSTM(128)(title_features)\n",
    "# Reduce sequence of embedded words in the body into a single 32-dimensional vector\n",
    "body_features = layers.LSTM(32)(body_features)\n",
    "\n",
    "# Merge all available features into a single large vector via concatenation\n",
    "x = layers.concatenate([title_features, body_features, tags_input])\n",
    "\n",
    "# Stick a logistic regression for priority prediction on top of the features\n",
    "priority_pred = layers.Dense(1, name=\"priority\")(x)\n",
    "# Stick a department classifier on top of the features\n",
    "department_pred = layers.Dense(num_departments, name=\"department\")(x)\n",
    "\n",
    "# Instantiate an end-to-end model predicting both priority and department\n",
    "model = keras.Model(\n",
    "    inputs=[title_input, body_input, tags_input],\n",
    "    outputs=[priority_pred, department_pred],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suffering-fabric",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "presidential-provision",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(1e-3),\n",
    "    loss=[\n",
    "        keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "        keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "    ],\n",
    "    loss_weights=[1.0, 0.2],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flush-brunei",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(1e-3),\n",
    "    loss={\n",
    "        \"priority\": keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "        \"department\": keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "    },\n",
    "    loss_weights={\"priority\": 1.0, \"department\": 0.2},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rapid-segment",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_data = np.random.randint(num_words, size=(1280, 10))\n",
    "body_data = np.random.randint(num_words, size=(1280, 100))\n",
    "tags_data = np.random.randint(2, size=(1280, num_tags)).astype(\"float32\")\n",
    "\n",
    "# Dummy target data\n",
    "priority_targets = np.random.random(size=(1280, 1))\n",
    "dept_targets = np.random.randint(2, size=(1280, num_departments))\n",
    "\n",
    "model.fit(\n",
    "    {\"title\": title_data, \"body\": body_data, \"tags\": tags_data},\n",
    "    {\"priority\": priority_targets, \"department\": dept_targets},\n",
    "    epochs=2,\n",
    "    batch_size=32,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loaded-bridge",
   "metadata": {},
   "source": [
    "When calling fit with a Dataset object, it should yield either a tuple of lists like ([title_data, body_data, tags_data], [priority_targets, dept_targets]) or a tuple of dictionaries like ({'title': title_data, 'body': body_data, 'tags': tags_data}, {'priority': priority_targets, 'department': dept_targets})."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worthy-infrared",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "inputs = keras.Input(shape=(32, 32, 3), name=\"img\")\n",
    "x = layers.Conv2D(32, 3, activation=\"relu\")(inputs)\n",
    "x = layers.Conv2D(64, 3, activation=\"relu\")(x)\n",
    "block_1_output = layers.MaxPooling2D(3)(x)\n",
    "\n",
    "x = layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(block_1_output)\n",
    "x = layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "block_2_output = layers.add([x, block_1_output])\n",
    "\n",
    "x = layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(block_2_output)\n",
    "x = layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "block_3_output = layers.add([x, block_2_output])\n",
    "\n",
    "x = layers.Conv2D(64, 3, activation=\"relu\")(block_3_output)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dense(256, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(10)(x)\n",
    "\n",
    "model = keras.Model(inputs, outputs, name=\"toy_resnet\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smart-series",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "\n",
    "x_train = x_train.astype(\"float32\") / 255.0\n",
    "x_test = x_test.astype(\"float32\") / 255.0\n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(1e-3),\n",
    "    loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[\"acc\"],\n",
    ")\n",
    "# We restrict the data to the first 1000 samples so as to limit execution time\n",
    "# on Colab. Try to train on the entire dataset until convergence!\n",
    "model.fit(x_train[:1000], y_train[:1000], batch_size=64, epochs=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "native-american",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shared layers\n",
    "# Embedding for 1000 unique words mapped to 128-dimensional vectors\n",
    "shared_embedding = layers.Embedding(1000, 128)\n",
    "\n",
    "# Variable-length sequence of integers\n",
    "text_input_a = keras.Input(shape=(None,), dtype=\"int32\")\n",
    "\n",
    "# Variable-length sequence of integers\n",
    "text_input_b = keras.Input(shape=(None,), dtype=\"int32\")\n",
    "\n",
    "# Reuse the same layer to encode both inputs\n",
    "encoded_input_a = shared_embedding(text_input_a)\n",
    "encoded_input_b = shared_embedding(text_input_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "under-champagne",
   "metadata": {},
   "source": [
    "### Extract and reuse nodes in the graph of layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quarterly-iraqi",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg19 = tf.keras.applications.VGG19()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secondary-printer",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list = [layer.output for layer in vgg19.layers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "popular-geography",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_extraction_model = keras.Model(inputs=vgg19.input, outputs=features_list)\n",
    "\n",
    "img = np.random.random((1, 224, 224, 3)).astype(\"float32\")\n",
    "extracted_features = feat_extraction_model(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "architectural-shareware",
   "metadata": {},
   "source": [
    "### Extend the API using custom layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "swiss-cassette",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDense(layers.Layer):\n",
    "    def __init__(self, units=32):\n",
    "        super(CustomDense, self).__init__()\n",
    "        self.units = units\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.w = self.add_weight(\n",
    "            shape=(input_shape[-1], self.units),\n",
    "            initializer=\"random_normal\",\n",
    "            trainable=True,\n",
    "        )\n",
    "        self.b = self.add_weight(\n",
    "            shape=(self.units,), initializer=\"random_normal\", trainable=True\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, self.w) + self.b\n",
    "\n",
    "\n",
    "inputs = keras.Input((4,))\n",
    "outputs = CustomDense(50)(inputs)\n",
    "\n",
    "model = keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "passing-entity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 4)]               0         \n",
      "                                                                 \n",
      " custom_dense_1 (CustomDense  (None, 50)               250       \n",
      " )                                                               \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 250\n",
      "Trainable params: 250\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convinced-valve",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDense(layers.Layer):\n",
    "    def __init__(self, units=32):\n",
    "        super(CustomDense, self).__init__()\n",
    "        self.units = units\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.w = self.add_weight(\n",
    "            shape=(input_shape[-1], self.units),\n",
    "            initializer=\"random_normal\",\n",
    "            trainable=True,\n",
    "        )\n",
    "        self.b = self.add_weight(\n",
    "            shape=(self.units,), initializer=\"random_normal\", trainable=True\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, self.w) + self.b\n",
    "\n",
    "    def get_config(self):\n",
    "        return {\"units\": self.units}\n",
    "\n",
    "\n",
    "inputs = keras.Input((4,))\n",
    "outputs = CustomDense(10)(inputs)\n",
    "\n",
    "model = keras.Model(inputs, outputs)\n",
    "config = model.get_config()\n",
    "\n",
    "new_model = keras.Model.from_config(config, custom_objects={\"CustomDense\": CustomDense})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dense-entrance",
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_config(cls, config):\n",
    "    return cls(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bizarre-regard",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's a quick example of a custom RNN, written from scratch, being used in a functional model:\n",
    "\n",
    "units = 32\n",
    "timesteps = 10\n",
    "input_dim = 5\n",
    "batch_size = 16\n",
    "\n",
    "\n",
    "class CustomRNN(layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(CustomRNN, self).__init__()\n",
    "        self.units = units\n",
    "        self.projection_1 = layers.Dense(units=units, activation=\"tanh\")\n",
    "        self.projection_2 = layers.Dense(units=units, activation=\"tanh\")\n",
    "        self.classifier = layers.Dense(1)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        outputs = []\n",
    "        state = tf.zeros(shape=(inputs.shape[0], self.units))\n",
    "        for t in range(inputs.shape[1]):\n",
    "            x = inputs[:, t, :]\n",
    "            h = self.projection_1(x)\n",
    "            y = h + self.projection_2(state)\n",
    "            state = y\n",
    "            outputs.append(y)\n",
    "        features = tf.stack(outputs, axis=1)\n",
    "        return self.classifier(features)\n",
    "\n",
    "\n",
    "# Note that you specify a static batch size for the inputs with the `batch_shape`\n",
    "# arg, because the inner computation of `CustomRNN` requires a static batch size\n",
    "# (when you create the `state` zeros tensor).\n",
    "inputs = keras.Input(batch_shape=(batch_size, timesteps, input_dim))\n",
    "x = layers.Conv1D(32, 3)(inputs)\n",
    "outputs = CustomRNN()(x)\n",
    "\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "rnn_model = CustomRNN()\n",
    "_ = rnn_model(tf.zeros((1, 10, 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "curious-revolution",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "registered-schedule",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
